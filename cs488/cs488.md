CS 488 (Exam Review)
=

> No shader questions, probably no coding questions. Set of [Sample Exam Questions](https://www.student.cs.uwaterloo.ca/~cs488/Fall2019/q.pdf), likely that a few appear on the exam. Questions that have not showed up on an exam in a long time are less likely to be asked.

2. History (Nothing).
3. Devices (Nothing).
4. Device Interfaces (Nothing).
5. [**Geometries**](#geometries) (Won't be tested in depth).
6. [**Affine Geometries & Transformations**](#affine-geometries-transformations).
7. [**Windows, Viewports, NDC**](#windows-viewports-ndc).
8. [**Line Clipping**](#line-clipping).
9. [**Projections**](#projections).
10. A2 (Nothing).
11. [**Polygons**](#polygons).
    - At least clipping, scan conversion (concept).
12. [**Hidden Surface Removal**](#hidden-surface-removal).
    - Backface Culling, Painter's Algorithm, Warnock, Z-Buffer.
13. [**Heirarchical Models & Transformations**](#heirarchical-models-transformations).
14. [**Rotations About Arbitrary Axis**](#rotations-about-arbitrary-axis).
    - Focused on Euler vs. Trackball.
15. Picking (Nothing)
16. [**Colour** (Minor things)](#colour).
17. [**Lighting**](#lighting).
    - Diffuse, specular.
18. [**Shading**](#shading).
    - Flat, Gouraud, Phong.
19. Graphics Hardware (Nothing).
20. ++ [**Ray Tracing**](#ray-tracing) ++
    - Around 30% of the exam.
    - Shadows, CSG, Texture / Bump Mapping.
21. [**Aliasing**](#aliasing).
22. [**Bidirectional Ray Tracing** (Not tested in depth)](#bidirectional-ray-tracing).
23. [**Radiosity** (Not tested in depth)](#radiosity).
24. [**Photon Mapping** (Not tested in depth)](#photon-mapping).
25. [**Shadows, Projective, Shadow Maps, Volumes** (Not tested in depth)](#25).
26. [**Modelling Stuff** (Short answers only if anything)](#modelling-stuff).
27. Polyhedral Data Structures (Nothing).
28. [**Splines, De Casteljau's Algorithm** (Lightly tested)](#splines-de-casteljaus-algorithm).
    - Know De Casteljau's.
29. [**Non-Photorealistic Rendering** (Very lightly tested)](#non-photorealistic-rendering).
30. Volume Rendering (Nothing).
31. [**Animation** (Might be short questions)](#animation).
32. Computational Geometry (Nothing).

## Geometries

### Vector Spaces

> Set of vectors $V$ with two operations.

1. **Addition**: $u + v \in V$.
2. **Scalar Multiplication**: $\alpha v \in V$, where $\alpha$ is a member of some field $\mathbb{F}$.

**Axioms**.

- **Addition Commutes**: $u + v = v + u$.
- **Addition Associates**: $(u + v) + w = u + (v + w)$.
- **Scalar Multiplication Distributes**: $\alpha(u + v) = \alpha u + \alpha v$.
- **Unique Zero Elements**: $0 + u = u$.
- **Field Unit Element**: $1 u = u$.

### Span

Suppose $B = \{v_1, v_2, ..., v_n\}$. $B$ **spans** $V$ if and only if any $v \in V$ can be written as $v = \sum_{i=1}^n \alpha_i v_i$ (**linear combination** of the vectors in $B$).

- Any minimal spanning set is a basis. All bases are the same size.
- The number of vectors in any basis is the **dimension**.

### Affine Spaces

> Now we use a set of points $P$ in addition to the set of vectors $V$.

- Points can be combined with vectors to make new points. $P + v \to Q$, with $P, Q \in P$ and $v \in V$.
- Basis now requires an affine extension. **Frame** is a vector basis plus a point $O$ (**origin**), with the same dimension as the basis.

**Inner Product Spaces**: Binary operator which is commutative, associative, scalar multiplication distributes, $u \cdot u \ge 0$ if and only if $u = 0$.

### Euclidean Spaces

**Metric Space**: Space with a **distance metric** $d(P, Q)$ defined. Requires distance be non-negative, zero if and only if the points are identical, commutative, and satisfy triangle inequality.

**Euclidean Space**: Metric space based on a dot (inner) product, $d^2(P, Q) = (P - Q) \cdot (P - Q)$.

- **Norm**: $|u| = \sqrt{u \cdot u}$.
- **Angle**: $cos(\angle u v) = \frac{u \cdot v}{|u||v|}$.
- **Perpendicularity**: $u \cdot v = 0 \Rightarrow u \perp v$. Perpendicularity is not an affine concept.

### Cartesian Space

An Euclidean Space with a standard **orthonormal frame** $(i, j, k, O)$.

- **Orthogonal**: $i \cdot j = j \cdot k = k \cdot i = 0$.
- **Normal**: $|i| = |j| = |k| = 1$.

> For notation, we specify the **Standard Frame** $F_s = (i, j, k, O)$.

Since points and vectors are different objects with different operations and behave differently under transformations how do we handle them?

**Coordinates**: We use an *extra coordinate*.

- $v = (v_x, v_y, v_z, 0)$.
- $P = (p_x, p_y, p_z, 1)$.

### Why Do We Need Affine Spaces?

- No metric, but we can add a metric to vector space.
- We want to represent objects efficiently, and we want to be able to translate, rotate, scale our objects in their representation. This is difficult to do with vectors.
    - For example, suppose we represent a position by the sum of two vectors. We cannot naively apply a translation to both vectors to translate the position.

## Affine Geometries & Transformations

### Linear Combinations

- Vector-Vector addition.
- $T(u + v) = T(u) + T(v)$. T(\alpha u) = \alpha T(u).
- Point-Vector addition.

### Affine Combinations

- **Point Subtraction**: $Q - P = v \in V$ such that $Q = P + v$, for $P, Q \in P$. So $\sum a_i P_i$ is a vector if and only if $\sum a_i = 0$.
- **Point Blending**: $Q = (1 - \alpha)Q_1 + \alpha Q_2$ such that $Q = Q_1 + \alpha(Q_2 - Q_1) \in P$. So $\sum a_i P_i$ is a point if and only if $\sum a_i = 1$.
    - $\frac{|Q - Q_1|}{|Q - Q_2|} = \frac{1 - \alpha}{\alpha}$.
- So when combining points, the result is a point if the coefficients sum to $1$, and the result is a vector if the coefficients sum to $0$.

### Affine Transformations

Let $T: A_1 \to A_2$, where $A_1, A_2$ are affine spaces.

- $T$ maps vectors to vectors and points to points.
- $T$ is a linear trasformation on the vectors.
- $T(P + u) = T(P) + T(u)$, where $P \in P$, $v \in V$.

Then $T$ is an affine transformation. Preserves affine combinations on the points.

Suppose $T$ is only defined on $P$. Then $T(v) = T(Q) - T(R)$, where $v = Q - R$.

### Mapping Through an Affine Transformation

Let $A, B$ be affine spaces, with $T: A \to B$ be an affine transformation. Let $F_A = (v_1, v_2, O_v)$ be a frame for $A$, let $F_B = (w_1, w_2, O_w)$ be a frame for $B$. Let$P$ be a point in $A$ whose *coordinates* relative to $F_A = (p_1, p_2, 1)$. What are the coordinates $(p_1^\prime, p_2^\prime, 1)$ of $T(P)$ relative to frame $F_B$?

$\begin{aligned}
T(P) &= T(p_1 v_1 + p_2 v_2 + O_v) \\
&= p_1T(v_1) + p_2 T(v_2) + T(O_v) \\
\end{aligned}$

### Geometric Transformations

- **Rotation**: $\begin{bmatrix}\cos(\theta) & -\sin(\theta) & 0 \\ \sin(\theta) & \cos(\theta) & 0\\ 0 & 0 & 1\end{bmatrix}$.
- **Shear**: $\begin{bmatrix}1 & \beta & 0 \\ \alpha & 1 & 0\\ 0 & 0 & 1\end{bmatrix}$.
- Translation is a shear in the next dimension.

### Change of Basis

Suppose we want to change coordinates relative to $F_1$ to coordinates relative to $F_2$. We know that $P = [x, y, 1]^T$ relative to $F_1 = (w_1, w_2, O_w)$. Solve $F_1 = F_2 M_{1, 2}$.

- When $F_2$ is orthonormal, $f_{i,j} = w_j \cdot v_i$, $f_{i,3} = (O_w - O_v) \cdot v_i$.
- Points "mapped" by a change of basis do not change, they are just represented in a different frame.
- To fully specify a transformation, we need a matrix, a domain space, a range space, and a coordinate frame in each space.

### World and Viewing Frames

- Standard frame is the **world frame**.
- Viewer may be anywhere and looking anywhere. Specified as $z, y$ with $z$ as the **view direction** and $z$ is the **up vector**.
- We change basis from the world frame to the viewers frame.

After we are in viewing coordinates, we place a clipping box around the scene relative to the viewing frame.

- The screen is 2D, so an **orthographic projection** is made by removing the z-coordinate.

### Transforming Normals

- Consider a non-uniform scale of a circle and the effect on the normal vector. The normal vector will be scaled as well which is incorrect.
- This is because normal vectors are **not** the difference in points.
    - But tangent vectors **are**, and normals are vectors perpendicular to all tangents at a point.
    - We can prove we should transform normals by the inverse transpose of the linear part of the transformation (upper 3 x 3 submatrix).
    - This is only an issue if there is a non-uniform scale or a shear transformation.

## Windows, Viewports, NDC

- **Window**: Rectangular area of interest in the scene.
- **Viewport**: Rectangular region on device.

Window to Viewport mapping is simple a scale based on the ratios and an offset based on their positions.

- When the ratios between the heights and lengths of the two regions are not the same, the image will be distorted.

### Normalized Device Coordinates

We want to specify the viewport in a generalized way so that it works on all plaforms / devices. So we use **Normalized Device Coordinates** as an intermediate coordinate system.

## Line Clipping

**Clipping** is removing points outside a region of interest.

- **Point clipping**: Points are either entirely inside the region or not.
- **Line clipping**: Halfspaces can be combined to bound a convex region.
    - Liang-Barsky algorithm efficiently clips line segments to a halfspace.
    - When a line segment is parially inside and partially outside a halfspace, we generate a new line to represent the part inside.

```python
for P, n in edges: # Halfspaces
    wecA = dot(A - P, n)
    wecB = dot(B - P, n)

    if wecA < 0 and wecB < 0:
        reject # Outside
    if wecA >= 0 and wecB >= 0:
        next # Inside

    t = wecA / (wecA - wecB)

    if wecA < 0:
        A = A + t * (B - A)
    else:
        B = A + t * (B - A)
```

## Projections

### Perspective Projection

- Identify all points with a line through the eyepoint.
- Take intersection with viewing plane as projection.
- This is **not** an affine transformation, but a perspective projection.
- Angles and distances are not preserved, but they are not preserved under affine transformations.
- Ratios of distances are not preserved, affine combinations are not preserved.
- Straight lines are mapped to straight lines.
- *Cross* ratios are preserved. $\frac{|AC| / |CD}{|AB| / |BC|}$.
- Compared to affine transformations, they require 1 extra point or vector $(n + 2)$ to define a projection map in $n$ dimensional space.

### Perspective Map

> For projection plane $z = d$.

- By similar triangles, $P = \left(\frac{xd}{z}, \frac{yd}{z}, d\right)$
- We need to know what is in front, which is impossible because the map loses $z$ information.
- $\begin{bmatrix}1 & 0 & 0 & 0 \\0 & 1 & 0 & 0\\0 & 0 & 1 & 1 \\ 0 & 0 & 1 & 0 \end{bmatrix}\begin{bmatrix}x \\y\\z\\1\end{bmatrix} = \begin{bmatrix}x\\y\\z+1\\z\end{bmatrix}$ maps $x, y$ to $\frac{x}{z}, \frac{y}{z}$, and maps $z$ to $1 + \frac{1}{z}$. So we retain depth information.
- $\begin{bmatrix}1 & 0 & 0 & 0 \\0 & 1 & 0 & 0\\0 & 0 & \frac{f+n}{f-n} & \frac{-2fn}{f-n} \\ 0 & 0 & 1 & 0 \end{bmatrix}\begin{bmatrix}x \\y\\z\\1\end{bmatrix} = \begin{bmatrix}x\\y\\\frac{z(f + n) - 2fn}{f - n}\\z\end{bmatrix}$ is used for mapping the near and far clipping planes to $[-1, 1]$.
- When fov-y is given, we need to include this in the matrix as $\cot(\theta / 2)$.

### 3D Clipping

- We should clip the near plane **before** projection to avoid divide by 0.
- Clipping to other planes *could* be done before projection but it is easier to clip after projection because we will have a cube instead of the truncated viewing pyramid.

## Polygons

> Area primitive.

- Simple polygon is planar set of ordered points, no holes, no crossing.
- Convention is to have points ordered in counter-clockwise order, so we have a defined interior and exterior.
- Affine transformations may introduce degeneracies. Orthographic projection may project entire polygon to a line segment.

### Polygon Clipping

- Window must be a convex polygon. Polygon to be clipped does not need to be convex.
- Given a polygon represented as $v_1,..., v_n$, we process all polygon edges in succession against a window edge, $w_1, ..., w_n$. Repeat for every window edge.

**Algorithm**: Four cases to consider.

1. Polygon edge is entirely inside the window edge. 
2. Polygon edge crosses window edge going out.
    - Intersection point $i$ is the next vertex of the resulting polygon.
3. Polygon edge is entirely outside the window edge.
    - No output.
4. Polygon edge crosses window going in.
    - Intersection point $i$ and $p$ are the next two vertices of the resulting polygon.

### Polygon Scan Conversion

- Complicated in general, we look at scan conversion of triangle.
- Split triangle with horizonal line at middle $y$ value, so we have an axis-aligned edge.
- Scan convert the triangle by calculating slopes and iterating over every horizontal line (floating point algorithm).

## Hidden Surface Removal

> When we have a lot of polygons, we want to draw only those visible to the viewer.

### Backface Culling

- Remove all *backfacing* polygons. Polygons are backfacing if their normal is facing away from the viewer. So cull the polygon if $N \cdot V > 0$.
- Not a complete solution (used in conjuction with more complete algorithm), but easy to integrate into hardware and usually improves performance by a factor of 2.

### Painter's Algorithm

- Sort polygons on farthest $z$.
- Resolve ambiguities where $z$'s overlap.
- Scan convert from largest $z$ to smallest $z$.
- Some cases are simple but others are not. $\Omega(n^2)$ algorithm.

### Warnock's Algorithm

> Divide and conquer algorithm.

- Draw the polygon-list if it is simple in the viewport, otherwise split the viewport vertically and horizontally then recursively draw.
- Simple means there is no more than one polygon in the viewport, or that the viewport is only 1 pixel in size (shade pixel based on closest polygon).
- $O(pn)$, where $p, n$ are the number of pixels and polygons.

### Z-Buffer Algorithm

- Perspective transformatoin maps polygons to polygons.
- Scan convert while also stepping in $z$.
- In addition to framebuffer, have a depth buffer ($z$ buffer) to write $z$ values.
- Update colour in framebuffer if the $z$ value is less than current.
- $O(p_c + n)$, where $p_c, n$ are the number of scan converted pixels and polygons.
- Easy to implement (hardware too), online algorithm.
- Doubles memory requirements (memory is cheap).
- Scale / device dependent.

## Heirarchical Models & Transformations

> How do we model complex objects and scenes?

## Rotations About Arbitrary Axis

## Colour

## Lighting

## Shading

## Ray Tracing

## Aliasing

## Bidirectional Ray Tracing

## Radiosity

## Photon Mapping

## Shadows, Projective, Shadow Maps, Volumes

## Modelling Stuff

## Splines, De Casteljau's Algorithm

## Non-Photorealistic Rendering

## Animation
