CS 486
=

## Rational Agent Paradigm

> An entity that perceives and acts.

- Function from percepts to actions.
- Performance measures.
    - Goal achievement, resource consumption.
- **Caveat**: Computational limitations and environmental constraints means we do not have perfect rationality.

### Task Environments

To design a rational agent the task environment must be defined.

- Performance measures.
- Environment.
- Actuators.
- Sensors.

#### Properties of Task Environment

- **Fully Observable** vs. **Partially Observable**.
- **Deterministic** vs. **Stochastic**.
    - Is the next state completely determined by the current state and action executed?
- **Episodic** vs. **Dynamic**.
- **Discrete** vs. **Continuous**.
- **Static** vs. **Dynamic**.
- **Single Agent** vs. **Multiagent**.

# Search

> **Search problem** consists of a **state space**, a **successor function**, a **start space**, and a **goal test**.

- **Solution** is a sequence of actions (plan) from the start state to some goal state.

**Example**: Sliding Tiles Problem.

> - **State**: Board configuration.
> - **Start**: Any state.
> - **Actions**: Slide the blank tile into an adjacent space.
> - **Goal**: Does it match picture?

**Example**: N Queens Problem.

> - **State**: $0$ to $N$ queens.
> - **Start**: $0$ queens.
> - **Actions**: Add a queen to an empty space.
> - **Goal**: $N$ queens none attacking.

Alternate representation which is more complicated but has a smaller search space.

> - **State**: $0$ to $N$ queens, first $n$ columns not attacking each other.
> - **Start**: $0$ queens.
> - **Actions**: Add a queen to the first empty column none attacking.
> - **Goal**: $N$ queens. And babu is cutie

## State Space

- The **world space** includes every last detial in the environment.
- A **search space** keeps only the details needed for planning (abstraction).

## Representing State

- **State space graph**.
    - Vertices correspond to states with one vertex for each space.
    - Edges correspond to successors.
    - Goal test is a set of goal nodes.
- We search for a solution by building a **search tree** and traversing it to find a goal state.

### Search Tree

- State state is the root of the tree.
- Children are the successors.
- Plan is a path in the tree. A solution is a path from the root to a goal node.

> For most problems we do not actually generate the entire tree.

- We expand a node by applying all legal actions on it and adding the new states to the tree.

### Generic Search Algorithm

- Initialize with initial state of the problem.
- **Repeat**.
    - If no candidate nodes, **faliure**.
    - Choose leaf node for expansion according to **search strategy**.
    - If node contains goal state, return **solution**.
    - Otherwise, expand the node. Add resulting nodes to the tree.
- Nodes can be classified as **start** node, **explored** nodes, **frontier**, **unexplored** nodes.
