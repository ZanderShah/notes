CS 486
=

## Rational Agent Paradigm

> An entity that perceives and acts.

- Function from percepts to actions.
- Performance measures.
    - Goal achievement, resource consumption.
- **Caveat**: Computational limitations and environmental constraints means we do not have perfect rationality.

### Task Environments

To design a rational agent the task environment must be defined.

- Performance measures.
- Environment.
- Actuators.
- Sensors.

#### Properties of Task Environment

- **Fully Observable** vs. **Partially Observable**.
- **Deterministic** vs. **Stochastic**.
    - Is the next state completely determined by the current state and action executed?
- **Episodic** vs. **Dynamic**.
- **Discrete** vs. **Continuous**.
- **Static** vs. **Dynamic**.
- **Single Agent** vs. **Multiagent**.

# Search

> **Search problem** consists of a **state space**, a **successor function**, a **start space**, and a **goal test**.

- **Solution** is a sequence of actions (plan) from the start state to some goal state.

**Example**: Sliding Tiles Problem.

> - **State**: Board configuration.
> - **Start**: Any state.
> - **Actions**: Slide the blank tile into an adjacent space.
> - **Goal**: Does it match picture?

**Example**: N Queens Problem.

> - **State**: $0$ to $N$ queens.
> - **Start**: $0$ queens.
> - **Actions**: Add a queen to an empty space.
> - **Goal**: $N$ queens none attacking.

Alternate representation which is more complicated but has a smaller search space.

> - **State**: $0$ to $N$ queens, first $n$ columns not attacking each other.
> - **Start**: $0$ queens.
> - **Actions**: Add a queen to the first empty column none attacking.
> - **Goal**: $N$ queens. And babu is cutie

## State Space

- The **world space** includes every last detial in the environment.
- A **search space** keeps only the details needed for planning (abstraction).

## Representing State

- **State space graph**.
    - Vertices correspond to states with one vertex for each space.
    - Edges correspond to successors.
    - Goal test is a set of goal nodes.
- We search for a solution by building a **search tree** and traversing it to find a goal state.

### Search Tree

- State state is the root of the tree.
- Children are the successors.
- Plan is a path in the tree. A solution is a path from the root to a goal node.

> For most problems we do not actually generate the entire tree.

- We expand a node by applying all legal actions on it and adding the new states to the tree.

## Generic Search Algorithm

- Initialize with initial state of the problem.
- **Repeat**.
    - If no candidate nodes, **faliure**.
    - Choose leaf node for expansion according to **search strategy**.
    - If node contains goal state, return **solution**.
    - Otherwise, expand the node. Add resulting nodes to the tree.
- Nodes can be classified as **start** node, **explored** nodes, **frontier**, **unexplored** nodes.

### Key Properties

- **Completeness**: Is the algorithm guaranteed to find a solution if one exists?
- **Optimality**: Does the algorithm find the optimal solution?
- **Time complexity**.
- **Space complexity**: Size of the fringe.
- $b$: Branching factor.
- $m$: Maximum depth.
- $d$: Depth of the nearest goal node.

**Example**: DFS.

> - **Complete**: No. Infinitely stuck in a loop. If $m$ is finite then it is.
> - **Optimal**: No. Finds the first goal, not necessarily the optimal.
> - **Time complexity**: Whole tree, $O(b^m)$.
> - **Space complexity**: Fringe and related path information. $O(m \cdot b)$.

**Example**: BFS.

> - **Complete**: Yes.
> - **Optimal**: Depends on whether the shallowest goal node is the one with the least cost.
> - **Time complexity**: Whole tree, $O(b^{d + 1})$.
> - **Space complexity**: $O(b^d)$.

### Iterative Deepened Search

> Combine search methods to take advantage of DFS space complexity and BFS completeness and shallow solution advantage?

- **Complete**: Yes.
- **Optimal**: Depends on whether the shallowest goal node is the one with the least cost.
- **Time complexity**: Whole tree, $O(b^d)$.
- **Space complexity**: $O(m \cdot b)$.

## Cost-Sensitive Search

### Uniform Cost Search

- **Strategy**: Expand cheapest node first.
- **Implementation**: Priority queue.
- **Complete**: Yes.
- **Optimal**: Yes if costs are all greater or less some $\epsilon$.
- **Time Complexity**: $O(b^{1 + \frac{C^*}{\epsilon}})$, where $C^*$ is the optimal cost.
- **Space Complexity**: Same as BFS.

# Informed Search

Uninformed search expands nodes on the distance from the start node. Why not try to expand on the distance to the goal?

## Heuristics

> A function that **estimates** the cost of reaching a goal from a given state.

- If $h(n_1) < h(n_2)$ we guess that it is cheaper to reach the goal from $n_1$ than $n_2$.
- We require $h(n, goal) = 0$.

**Example**: Best First Search.

> **Search strategy**: Expand the most promising node according to the heuristic.
