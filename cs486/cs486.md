CS 486
=

## Rational Agent Paradigm

> An entity that perceives and acts.

- Function from percepts to actions.
- Performance measures.
    - Goal achievement, resource consumption.
- **Caveat**: Computational limitations and environmental constraints means we do not have perfect rationality.

### Task Environments

To design a rational agent the task environment must be defined.

- Performance measures.
- Environment.
- Actuators.
- Sensors.

#### Properties of Task Environment

- **Fully Observable** vs. **Partially Observable**.
- **Deterministic** vs. **Stochastic**.
    - Is the next state completely determined by the current state and action executed?
- **Episodic** vs. **Dynamic**.
- **Discrete** vs. **Continuous**.
- **Static** vs. **Dynamic**.
- **Single Agent** vs. **Multiagent**.

# Search

> **Search problem** consists of a **state space**, a **successor function**, a **start space**, and a **goal test**.

- **Solution** is a sequence of actions (plan) from the start state to some goal state.

**Example**: Sliding Tiles Problem.

> - **State**: Board configuration.
> - **Start**: Any state.
> - **Actions**: Slide the blank tile into an adjacent space.
> - **Goal**: Does it match picture?

**Example**: N Queens Problem.

> - **State**: $0$ to $N$ queens.
> - **Start**: $0$ queens.
> - **Actions**: Add a queen to an empty space.
> - **Goal**: $N$ queens none attacking.

Alternate representation which is more complicated but has a smaller search space.

> - **State**: $0$ to $N$ queens, first $n$ columns not attacking each other.
> - **Start**: $0$ queens.
> - **Actions**: Add a queen to the first empty column none attacking.
> - **Goal**: $N$ queens. And babu is cutie

## State Space

- The **world space** includes every last detial in the environment.
- A **search space** keeps only the details needed for planning (abstraction).

## Representing State

- **State space graph**.
    - Vertices correspond to states with one vertex for each space.
    - Edges correspond to successors.
    - Goal test is a set of goal nodes.
- We search for a solution by building a **search tree** and traversing it to find a goal state.

### Search Tree

- State state is the root of the tree.
- Children are the successors.
- Plan is a path in the tree. A solution is a path from the root to a goal node.

> For most problems we do not actually generate the entire tree.

- We expand a node by applying all legal actions on it and adding the new states to the tree.

## Generic Search Algorithm

- Initialize with initial state of the problem.
- **Repeat**.
    - If no candidate nodes, **faliure**.
    - Choose leaf node for expansion according to **search strategy**.
    - If node contains goal state, return **solution**.
    - Otherwise, expand the node. Add resulting nodes to the tree.
- Nodes can be classified as **start** node, **explored** nodes, **frontier**, **unexplored** nodes.

### Key Properties

- **Completeness**: Is the algorithm guaranteed to find a solution if one exists?
- **Optimality**: Does the algorithm find the optimal solution?
- **Time complexity**.
- **Space complexity**: Size of the fringe.
- $b$: Branching factor.
- $m$: Maximum depth.
- $d$: Depth of the nearest goal node.

**Example**: DFS.

> - **Complete**: No. Infinitely stuck in a loop. If $m$ is finite then it is.
> - **Optimal**: No. Finds the first goal, not necessarily the optimal.
> - **Time complexity**: Whole tree, $O(b^m)$.
> - **Space complexity**: Fringe and related path information. $O(m \cdot b)$.

**Example**: BFS.

> - **Complete**: Yes.
> - **Optimal**: Depends on whether the shallowest goal node is the one with the least cost.
> - **Time complexity**: Whole tree, $O(b^{d + 1})$.
> - **Space complexity**: $O(b^d)$.

### Iterative Deepened Search

> Combine search methods to take advantage of DFS space complexity and BFS completeness and shallow solution advantage?

- **Complete**: Yes.
- **Optimal**: Depends on whether the shallowest goal node is the one with the least cost.
- **Time complexity**: Whole tree, $O(b^d)$.
- **Space complexity**: $O(m \cdot b)$.

## Cost-Sensitive Search

### Uniform Cost Search

- **Strategy**: Expand cheapest node first.
- **Implementation**: Priority queue.
- **Complete**: Yes.
- **Optimal**: Yes if costs are all greater or less some $\epsilon$.
- **Time Complexity**: $O(b^{1 + \frac{C^*}{\epsilon}})$, where $C^*$ is the optimal cost.
- **Space Complexity**: Same as BFS.

# Informed Search

Uninformed search expands nodes on the distance from the start node. Why not try to expand on the distance to the goal?

## Heuristics

> A function that **estimates** the cost of reaching a goal from a given state.

- If $h(n_1) < h(n_2)$ we guess that it is cheaper to reach the goal from $n_1$ than $n_2$.
- We require $h(n, goal) = 0$.

**Example**: Best First Search.

> **Search strategy**: Expand the most promising node according to the heuristic.

## Missing Lecture (Friday 13)

# Constraint Satisfaction

> Special subset of search problems.

- **States** are defined by **variables** $X_i$ with values from **domains** $D_i$.
- **Goal test** is a **set of constraints** specifying allowable combinations of values for subsets of variables.

## Types of CPSs

- **Discrete variables**.
    - **Finite domains**. If domain has size $d$, there are $O(d^n)$ complete assignments.
    - **Infinite domains**. Linear constraints are solvable but non-linear are undecidable.
- **Continuous variables**. Linear programming polynomial time.
- **Unary constraints**.
- **Binary constraints**. Representable with a constraint graph.
- **Higher-order constraints**.
- **Soft constraints**. Constrained optimization problem.

## Commutativity

> **Key insight** is that CPSs are commutative.

- Order of actions do not affect outcome.
- Algorithm takes advantage of this.

## Backtracking

> Basic search algorithm for CSPs.

```
Select unassigned variable X
For every value {x_1, ..., x_n} in domain of X
    If value satisfies constraints, assign X = x_i and exit loop
If an assignment is found
    Move to next variable
If no assignment is found
    Back up to preceding variable and try a different assignment
```

### Backtracking Efficiency

#### Ordering

> Which variables should be tried first? In what order should the variable's values be tried?

- **Most constrained variable**. Try the variable with the fewest remaining *legal* moves. Also known as **minimum remaining values**.
- **Most constraining variable**. Try the variable with the most constraints on the remaining variables.
- **Least constraining variable**. Try the variable which rules out the fewest values in the remaining variables.

#### Filtering

> How do we detect faliure early?

- **Forward checking**. Keep track of remaining legal values for unassigned varibles. Terminate search when any variable has no legal values.
    - Does not detect all future faliures early.
- **Arc consistency**. Given domains $D_1, D_2$, an arc is consistent if for all $x \in D_1$, there exists $y \in D_2$ such that $x, y$ are consistent.
- **K-consistency**. For all sets of $K - 1$ variables and consistent assignment of values, a consistent value is always assignable to any $K$th variable.

#### Structure

> Is it possible to exploit the problem structure?

- **Idea**. Break down the graph into connected components and solve each component separately.
