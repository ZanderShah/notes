CS 240
=

# Algorithm Design

**Problem**: Given a problem instance, carry out a particular computational task.

**Problem Instance**: Input.

**Problem Solution**: Output.

**Size of a problem instance**: Size(I) is a positive integer that measures the size of instance I.

**Algorithm**: Step-by-step process for carrying out a series of computations, given an abitrary problem instance I.

For a problem $\Pi$, we can have several algorithms. For an algorithm $A$ solving $\Pi$, we can have several programs (implementations).

* Designing an algorithm $A$ that solves $\Pi$ -> **Algorithm Design**.
* Assessing correctness and efficiency of $A$ -> **Algorithm Analysis**.

# Analysis of Algorithms I

We may be interested in the amount of **time** or **memory**. Experimental shortcomings have shortcomings because of implementations, hardware, and testing against all inputs.

Instead we write code for Random Access Machines (RAM)

* Set of memory cells, each of which stores one item of data.
* Access to memory in O(1).
* Primitive operations are O(1).
* Runtime of a program is the number of memory accesses + the number of primitive operations.

The efficiency is measured in terms of it's **growth rate** (this is called the **complexity** of the algorithm).

```python
for i in range(n):
  for j in range(n):
    c[i][j] = 0
    for k in range(n):
      c[i][j] += a[i][k] * b[k][j]
```
*About* $n^3$ operations.

# Asymptotic Notation
O-Notation $f(n) \in O(g(n))$ if there exists constants $c > 0, n_0 > 0$ such that if $|f(n)| \le c|g(n)|$ $\forall n \ge n_0$.

Example: $f(n) = 75n + 500$ and $g(n) = 5n^2$.

> $f(n), g(n) \ge 0$ $\forall n \ge 1$    
> For $n \ge 20$    
> $n^2 \ge 20n$    
> $5n^2 \ge 100n$    
> $25n \ge 25 * 20 = 500$    
> $5n^2 \ge 75n + 500$    
> $g(n) \ge f(n)$    
> Taking $n_0 = 20, c = 1$, this proves that $f(n) \in O(g(n))$.    

We want a **tight** asymptotic bound.

$\Omega$-notation: $f(n) \in \omega(g(n))$ if $\exists c > 0, n_0 > 0$ such that $c|g(n)| \le |f(n)| \forall n \ge n_0$.

$\Theta$-notation: $\exists c1, c2 \ge 0, n_0 > 0$ such that $c1|g(n)| \le |f(n)| \le c2|g(n)| \forall n \ge n_0$.

How to express $f(n)$ is asymptotically strictly smaller than $g(n)$?

o-notation: $\forall c > 0, \exists n_0 > 0$ such that $|f(n)| < c|g(n)| \forall n \ge n_0$.

$\omega$-notation: $\forall c > 0, \exists n_0 > 0$ such that $0 \le c|g(n)| < f(n) \forall n \ge n_0$.

Example: $f(n) = 2000n^2 + 5000n$ and $g(n) = n^3$. Prove $f(n) \in o(g(n))$.

> Given $c > 0$, for $n > 0$, $f(n) = 2000n^2 + 5000n \le 7000n^2$.    
> $7000n^2 < cn^3 \Leftrightarrow 7000 < cn \Leftrightarrow n > \frac{7000}{c}$    
> So if we take $n_0 = \frac{7000}{c} + 1$, we have $f(n) < g(n) \forall n \ge n_0$. This proves that $f(n) \in o(g(n))$.    

## Asymptotic Identities

> $f(n) \in \Theta(g(n)) \Leftrightarrow g(n) \in \Theta(f(n))$    
> $f(n) \in O(g(n)) \Leftrightarrow g(n) \in \Omega(f(n))$    
> $f(n) \in o(g(n)) \Rightarrow f(n) \in O(g(n)), \nRightarrow f(n) \in \Omega(g(n))$    
> $f(n) \in \omega(g(n)) \Rightarrow f(n) \in \Omega(g(n)), \Rightarrow f(n) \notin O(g(n))$    
> *Identitity*: $f(n) \in \Theta(f(n))$    
> *Maximum*: $f(n) > 0, g(n) > 0 \forall n \ge n_0 \Rightarrow O(f(n) + g(n)) = O(\max\{f(n), g(n)\})$. Similar for $\Omega$.    
> *Transitivity*: $f(n) \in O(g(n)), g(n) \in O(h(n)) \Rightarrow f(n) \in O(h(n))$. Similar for $\Omega$.    

## Limit Test

Suppose $L = \lim_{n \to \infty} \frac{f(n)}{g(n)}$.    
If $L = 0$, $f(n) \in o(g(n))$.    
If $0 < L < \infty$, $f(n) \in \Theta(g(n))$.    
If $L = \infty$, $f(n) \in \omega(g(n))$.    
