CS 370
=

# Floating Point

Computers have a limited amount of memory, they cannot represent all numbers.

$$S \subset \mathbb{R}$$

Assume we want to compute $e^{-5.5}$. Using the Taylor expansion, we know that $e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + ...$. We cannot include infinite terms, so we need to make an approximation. This will lead to a result of 0.0026363.

However, if we use $e^{-x} = \frac{1}{1 + x + \frac{x^2}{2!} + ...}$, we will get a result of 0.0040865 which is much closer to the true value.

Let us consider the number 12.25. This is equal to $1\cdot 10 + 2\cdot 10^0 + 2\cdot 10^{-1} + 5\cdot10^{-5}$. We can generalize this as $d_k \in \{0, 1, ..., 9\}$ with $d_0d_1...d_{j-1}.d_jd_{j+1}...d_{j+i-1}$and is represented as $d_0\cdot 10^{j-1} + d_1\cdot 10^{j-2} + ... + d_{j+i-1} \cdot 10^{-i}$. Computers only understand bits, so $d_k \in \{0, 1\}$. So instead we have $(\sum_{k=0}^{j+i-1}d_k\cdot 2^{-k})\cdot 2^{j-1}$. We have some limitations because $j, i$ cannot be arbitrarily large.
