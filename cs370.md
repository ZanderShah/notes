CS 370
=

# Floating Point

Computers have a limited amount of memory, they cannot represent all numbers.

$$S \subset \mathbb{R}$$

Assume we want to compute $e^{-5.5}$. Using the Taylor expansion, we know that $e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + ...$. We cannot include infinite terms, so we need to make an approximation. This will lead to a result of 0.0026363.

However, if we use $e^{-x} = \frac{1}{1 + x + \frac{x^2}{2!} + ...}$, we will get a result of 0.0040865 which is much closer to the true value.

Let us consider the number 12.25. This is equal to $1\cdot 10 + 2\cdot 10^0 + 2\cdot 10^{-1} + 5\cdot10^{-5}$. We can generalize this as $d_k \in \{0, 1, ..., 9\}$ with $d_0d_1...d_{j-1}.d_jd_{j+1}...d_{j+i-1}$and is represented as $d_0\cdot 10^{j-1} + d_1\cdot 10^{j-2} + ... + d_{j+i-1} \cdot 10^{-i}$. Computers only understand bits, so $d_k \in \{0, 1\}$. So instead we have $(\sum_{k=0}^{j+i-1}d_k\cdot 2^{-k})\cdot 2^{j-1}$. We have some limitations because $j, i$ cannot be arbitrarily large.

We need to truncate, we decide an upper bound on the exponent and the number of significant digits we can represent.

### What numbers can we represent?

Example: $\beta = 2, m = 3$. $d_k \in \{0, 1\}, 0 \le j \le 3$.

$$\overline{x} = \left(\sum_{k=0}^2 d_k 2^{-k}\right)\cdot 2^{j-1}$$

Assume $d_0 > 0$, so $d_0 = 1$ (normalized floating point convention). We can simplify the above expression.

$$\overline{x} = 2^{j-1} + \left(\sum_{k=1}^2 d_k 2^{-k}\right)\cdot 2^{j-1}$$

We minimize $\overline{x}$ with $j=0, d_k = 0$. We maximize with $j=3, d_k = 1$.

In general, given $\beta, m, j_{max}, j_{min}$, the minimum is $\beta^{j_{min} - 1}$ and the maximum is $(\beta - \beta^{1 - m}) \cdot \beta^{j_{max}}$. So all numbers are in the range of $[\beta^{j_{min} - 1}, (\beta - \beta^{1 - m})\cdot \beta^{j_{max}}]$.

The minimum significant is 1, and the maximum significant is $\beta$.
